import os
import io
import time
import datetime
import tempfile

import requests
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw
import streamlit as st

from reportlab.lib.pagesizes import A4
from reportlab.platypus import (
    SimpleDocTemplate,
    Paragraph,
    Spacer,
    Image as RLImage,
    Table,
    TableStyle,
)
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet

# =========================================================
# 1. C·∫§U H√åNH ROBOFLOW
# =========================================================
# Copy nguy√™n link Hosted API t·ª´ Roboflow (Deploy -> Hosted API -> Python)
# V√≠ d·ª•:
#   "https://detect.roboflow.com/crack_segmentation_detection/4?api_key=xxxx"
ROBOFLOW_FULL_URL ="https://detect.roboflow.com/crack_segmentation_detection/4?api_key=nWA6ayjI5bGNpXkkbsAb"


# =========================================================
# 2. LOGO & BRAND BKAI
# =========================================================
BKAI_LOGO = "bkai_logo.png"
BKAI_SITE = "https://bkai.b12sites.com/index"


def show_logo(size: int = 100):
    """Hi·ªÉn th·ªã logo BKAI ho·∫∑c link website."""
    if os.path.exists(BKAI_LOGO):
        st.image(BKAI_LOGO, width=size)
    else:
        st.markdown(f"[üåê BKAI Website]({BKAI_SITE})")


# =========================================================
# 3. H√ÄM H·ªñ TR·ª¢ X·ª¨ L√ù ·∫¢NH & PREDICTIONS
# =========================================================
def resize_for_speed(img: Image.Image, max_side: int):
    """Resize ·∫£nh nh∆∞ng gi·ªØ t·ªâ l·ªá, c·∫°nh d√†i nh·∫•t = max_side (n·∫øu > max_side)."""
    w, h = img.size
    max_dim = max(w, h)
    if max_dim <= max_side:
        return img, 1.0
    scale = max_side / max_dim
    new_size = (int(w * scale), int(h * scale))
    return img.resize(new_size), scale


def extract_points(points_field):
    """Chuy·ªÉn tr∆∞·ªùng 'points' t·ª´ JSON c·ªßa Roboflow th√†nh list [(x,y), ...]."""
    flat = []
    if isinstance(points_field, dict):
        for k in sorted(points_field.keys()):
            seg = points_field[k]
            if isinstance(seg, list):
                for pt in seg:
                    if isinstance(pt, (list, tuple)) and len(pt) == 2:
                        flat.append((pt[0], pt[1]))
    elif isinstance(points_field, list):
        for pt in points_field:
            if isinstance(pt, (list, tuple)) and len(pt) == 2:
                flat.append((pt[0], pt[1]))
    return flat


def draw_predictions(image: Image.Image, predictions, min_conf: float):
    """
    V·∫Ω:
      - Mask ƒë·ªè trong su·ªët (instance segmentation) n·∫øu c√≥ points
      - Box xanh
      - Label 'crack 0.xx' nh∆∞ Ultralytics
    """
    base = image.convert("RGBA")
    draw = ImageDraw.Draw(base)
    mask_layer = Image.new("RGBA", base.size, (0, 0, 0, 0))
    mask_draw = ImageDraw.Draw(mask_layer)

    blue = (0, 180, 255)
    red_fill = (255, 0, 0, 80)
    red_outline = (255, 0, 0, 180)

    for p in predictions:
        conf = float(p.get("confidence", 0))
        if conf < min_conf:
            continue

        x, y, w, h = p["x"], p["y"], p["width"], p["height"]
        x0, y0, x1, y1 = x - w / 2, y - h / 2, x + w / 2, y + h / 2

        # Mask t·ª´ polygon
        pts = extract_points(p.get("points", []))
        if len(pts) >= 3:
            mask_draw.polygon(pts, fill=red_fill, outline=red_outline)
        elif len(pts) >= 2:
            mask_draw.line(pts, fill=red_outline, width=3)

        # Box
        draw.rectangle([x0, y0, x1, y1], outline=blue, width=3)

        # Label
        label = f"{p.get('class', 'crack')} {conf:.2f}"
        label_bg_w = 90
        label_bg_h = 18
        draw.rectangle([x0, y0 - label_bg_h, x0 + label_bg_w, y0], fill=blue)
        draw.text((x0 + 3, y0 - label_bg_h + 2), label, fill="white")

    return Image.alpha_composite(base, mask_layer).convert("RGB")


def estimate_severity(p, img_w, img_h):
    """∆Ø·ªõc l∆∞·ª£ng m·ª©c ƒë·ªô nghi√™m tr·ªçng t·ª´ di·ªán t√≠ch box / di·ªán t√≠ch ·∫£nh."""
    w, h = float(p["width"]), float(p["height"])
    ratio = (w * h) / (img_w * img_h)
    if ratio < 0.01:
        return "Nh·ªè / Small"
    elif ratio < 0.05:
        return "Trung b√¨nh / Medium"
    else:
        return "L·ªõn / Large"


# =========================================================
# 4. H√ÄM XU·∫§T PDF B√ÅO C√ÅO
# =========================================================
def export_report_pdf(
    pdf_path,
    original_path,
    annotated_path,
    df_summary,
    chart_path,
    title="BKAI ‚Äì B√°o c√°o ki·ªÉm tra v·∫øt n·ª©t b√™ t√¥ng / Concrete Crack Inspection Report",
):
    """
    T·∫°o file PDF b√°o c√°o:
      - Logo, ti√™u ƒë·ªÅ
      - ·∫¢nh g·ªëc + ·∫£nh k·∫øt qu·∫£
      - B·∫£ng t·ªïng quan song ng·ªØ
      - Bi·ªÉu ƒë·ªì confidence (bar/pie)
    """
    doc = SimpleDocTemplate(pdf_path, pagesize=A4)
    styles = getSampleStyleSheet()
    story = []

    # Ti√™u ƒë·ªÅ
    story.append(Paragraph(f"<b>{title}</b>", styles["Title"]))
    story.append(Spacer(1, 12))

    # Th·ªùi gian
    now_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    story.append(Paragraph(f"Th·ªùi gian / Generated at: {now_str}", styles["Normal"]))
    story.append(Spacer(1, 12))

    # ·∫¢nh g·ªëc + ·∫£nh k·∫øt qu·∫£
    story.append(Paragraph("<b>·∫¢nh g·ªëc / Original Image</b>", styles["Heading3"]))
    story.append(RLImage(original_path, width=260, height=180))
    story.append(Spacer(1, 12))

    story.append(Paragraph("<b>·∫¢nh k·∫øt qu·∫£ / Analyzed Image</b>", styles["Heading3"]))
    story.append(RLImage(annotated_path, width=260, height=180))
    story.append(Spacer(1, 18))

    # B·∫£ng t·ªïng quan
    story.append(
        Paragraph("<b>B√°o c√°o t·ªïng quan / Summary Analysis</b>", styles["Heading3"])
    )
    data = [df_summary.columns.tolist()] + df_summary.values.tolist()
    table = Table(data)
    table.setStyle(
        TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#0ea5e9")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                ("INNERGRID", (0, 0), (-1, -1), 0.25, colors.black),
                ("BOX", (0, 0), (-1, -1), 0.25, colors.black),
            ]
        )
    )
    story.append(table)
    story.append(Spacer(1, 18))

    # Bi·ªÉu ƒë·ªì
    story.append(
        Paragraph(
            "<b>Bi·ªÉu ƒë·ªì ƒë·ªô tin c·∫≠y / Confidence Charts</b>", styles["Heading3"]
        )
    )
    story.append(RLImage(chart_path, width=400, height=230))
    story.append(Spacer(1, 12))

    # Footer
    story.append(
        Paragraph(
            "BKAI ¬© 2025 ‚Äì Powered by AI for Construction Excellence",
            styles["Normal"],
        )
    )

    doc.build(story)
    return pdf_path


# =========================================================
# 5. GIAO DI·ªÜN STREAMLIT
# =========================================================
st.set_page_config(page_title="BKAI Crack Inspection Pro", layout="wide")

# Dark theme nh·∫π
st.markdown(
    """
<style>
body { background-color: #020617; color: #e5e7eb; }
.block-container { padding-top: 1.2rem; padding-bottom: 1.2rem; }
h1, h2, h3 { color: #0ea5e9; }
table, th, td { color: #e5e7eb !important; }
</style>
""",
    unsafe_allow_html=True,
)

# Sidebar
with st.sidebar:
    show_logo(130)
    st.markdown("### ‚öôÔ∏è C·∫•u h√¨nh / Settings")
    min_conf = st.slider(
        "Ng∆∞·ª°ng confidence / Confidence threshold",
        0.0,
        1.0,
        0.3,
        0.05,
    )
    max_side = st.slider(
        "K√≠ch th∆∞·ªõc ·∫£nh t·ªëi ƒëa / Max image size (px)",
        400,
        1600,
        900,
        100,
    )
    st.caption(
        "·∫¢nh l·ªõn s·∫Ω ƒë∆∞·ª£c thu nh·ªè v·ªÅ k√≠ch th∆∞·ªõc n√†y ƒë·ªÉ tƒÉng t·ªëc x·ª≠ l√Ω.\n"
        "Large images will be resized to speed up inference."
    )

# Header
col_logo, col_title = st.columns([1, 4])
with col_logo:
    show_logo(80)
with col_title:
    st.title(
        "üß† BKAI ‚Äì B√°o c√°o ki·ªÉm tra v·∫øt n·ª©t b√™ t√¥ng / Concrete Crack Inspection Report"
    )

st.markdown(
    """
·ª®ng d·ª•ng s·ª≠ d·ª•ng **m√¥ h√¨nh AI c·ªßa BKAI + Roboflow** ƒë·ªÉ:
- üü• T√¥ **v√πng n·ª©t** ƒë·ªè trong su·ªët (Instance Segmentation)
- üü¶ Khoanh v√πng b·∫±ng **box xanh** + label `crack 0.xx`
- üìä T·∫°o **b·∫£ng t·ªïng quan** + **b·∫£ng chi ti·∫øt** v·∫øt n·ª©t (song ng·ªØ)
- üìà V·∫Ω **nhi·ªÅu d·∫°ng bi·ªÉu ƒë·ªì** (bar + pie) v·ªÅ ƒë·ªô tin c·∫≠y
- üìÑ Xu·∫•t **PDF b√°o c√°o** ƒë·∫ßy ƒë·ªß cho t·ª´ng ·∫£nh
"""
)

# Upload
uploaded_files = st.file_uploader(
    "üìÇ Ch·ªçn 1 ho·∫∑c nhi·ªÅu ·∫£nh b√™ t√¥ng (JPG/PNG) / Select one or multiple images",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True,
)

# =========================================================
# 6. X·ª¨ L√ù T·ª™NG ·∫¢NH
# =========================================================
if uploaded_files:
    for idx, up in enumerate(uploaded_files, start=1):
        st.write("---")
        st.markdown(f"## üñºÔ∏è ·∫¢nh {idx}: `{up.name}`")

        # ƒê·ªçc & resize ·∫£nh
        image = Image.open(up).convert("RGB")
        image, scale = resize_for_speed(image, max_side)
        img_w, img_h = image.size

        # Encode ·∫£nh
        buf = io.BytesIO()
        image.save(buf, format="JPEG")
        img_bytes = buf.getvalue()

        # G·ªçi API
        with st.spinner("‚è≥ ƒêang ph√¢n t√≠ch ·∫£nh v·ªõi AI BKAI... / Analyzing image..."):
            t0 = time.time()
            try:
                resp = requests.post(
                    ROBOFLOW_FULL_URL,
                    files={"file": ("image.jpg", img_bytes, "image/jpeg")},
                    timeout=60,
                )
            except Exception as e:
                st.error(f"L·ªói khi g·ªçi API Roboflow: {e}")
                continue
            latency = time.time() - t0

        if resp.status_code != 200:
            st.error(f"Roboflow API tr·∫£ l·ªói {resp.status_code}")
            st.text(resp.text[:500])
            continue

        try:
            result = resp.json()
        except Exception as e:
            st.error(f"Kh√¥ng parse ƒë∆∞·ª£c JSON tr·∫£ v·ªÅ: {e}")
            st.text(resp.text[:500])
            continue

        preds = result.get("predictions", [])
        preds_conf = [p for p in preds if p.get("confidence", 0) >= min_conf]

        # Hi·ªÉn th·ªã ·∫£nh
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("·∫¢nh g·ªëc / Original")
            st.image(image, use_column_width=True)
        with col2:
            st.subheader("·∫¢nh k·∫øt qu·∫£ / Analyzed")
            if preds_conf:
                annotated = draw_predictions(image, preds_conf, min_conf)
                st.image(annotated, use_column_width=True)
                st.error("‚ö†Ô∏è C√≥ v·∫øt n·ª©t / Crack detected")
            else:
                annotated = image.copy()
                st.image(annotated, use_column_width=True)
                st.success("‚úÖ Kh√¥ng ph√°t hi·ªán v·∫øt n·ª©t ƒë√°ng k·ªÉ / No significant crack")

        # N·∫øu kh√¥ng c√≥ b·∫•t k·ª≥ prediction n√†o, b·ªè qua b√°o c√°o chi ti·∫øt
        if not preds:
            st.info("Model kh√¥ng ph√°t hi·ªán v√πng n√†o / No predictions from model.")
            continue

        # =====================================================
        # 6.1 B√ÅO C√ÅO T·ªîNG QUAN (SONG NG·ªÆ)
        # =====================================================
        confs_all = [float(p["confidence"]) for p in preds]
        avg_conf = sum(confs_all) / len(confs_all)
        max_conf = max(confs_all)
        min_conf_pred = min(confs_all)

        area_crack = sum(float(p["width"]) * float(p["height"]) for p in preds_conf)
        coverage = (area_crack / (img_w * img_h)) * 100 if img_w * img_h > 0 else 0.0

        conclusion = (
            "C√≥ v·∫øt n·ª©t / Crack detected"
            if preds_conf
            else "Kh√¥ng c√≥ v·∫øt n·ª©t r√µ r√†ng / No clear crack"
        )

        df_summary = pd.DataFrame(
            [
                [
                    "K·∫øt lu·∫≠n / Conclusion",
                    conclusion,
                    "ƒê√°nh gi√° t·ªïng th·ªÉ t·ª´ c√°c v√πng ph√°t hi·ªán / Overall assessment",
                ],
                [
                    "S·ªë v√πng ph√°t hi·ªán / Total regions",
                    len(preds),
                    "T·∫•t c·∫£ v√πng model ph√°t hi·ªán / All predictions",
                ],
                [
                    "S·ªë v√πng ƒë·∫°t ng∆∞·ª°ng / Regions ‚â• threshold",
                    len(preds_conf),
                    f"Confidence ‚â• {min_conf:.2f}",
                ],
                [
                    "ƒê·ªô tin c·∫≠y TB / Avg confidence",
                    f"{avg_conf:.3f}",
                    "Trung b√¨nh tr√™n t·∫•t c·∫£ v√πng / Average over all regions",
                ],
                [
                    "ƒê·ªô tin c·∫≠y cao nh·∫•t / Max confidence",
                    f"{max_conf:.3f}",
                    "",
                ],
                [
                    "ƒê·ªô tin c·∫≠y th·∫•p nh·∫•t / Min confidence",
                    f"{min_conf_pred:.3f}",
                    "",
                ],
                [
                    "ƒê·ªô ph·ªß v·∫øt n·ª©t / Surface coverage",
                    f"{coverage:.2f} %",
                    "T·ªâ l·ªá di·ªán t√≠ch box so v·ªõi ·∫£nh / Crack area ratio",
                ],
                [
                    "Th·ªùi gian x·ª≠ l√Ω / Processing time",
                    f"{latency:.2f} s",
                    "Bao g·ªìm upload + inference / Including upload + inference",
                ],
                [
                    "K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω / Image size",
                    f"{img_w} √ó {img_h} px",
                    "Sau khi resize / After resizing",
                ],
                [
                    "Ng∆∞·ª°ng confidence / Threshold",
                    f"{min_conf:.2f}",
                    "",
                ],
                [
                    "F1-score",
                    "N/A",
                    "C·∫ßn t·∫≠p test c√≥ ground truth / Requires labeled test set",
                ],
                [
                    "mAP",
                    "N/A",
                    "Kh√¥ng t√≠nh t·ª´ 1 ·∫£nh / Not computed per single image",
                ],
            ],
            columns=["Ch·ªâ s·ªë / Indicator", "Gi√° tr·ªã / Value", "Ghi ch√∫ / Notes"],
        )

        st.subheader("üìä B√°o c√°o t·ªïng quan / Summary report")
        st.table(df_summary)

        # =====================================================
        # 6.2 CHI TI·∫æT V·∫æT N·ª®T
        # =====================================================
        details = []
        for i_p, p in enumerate(preds_conf, start=1):
            details.append(
                {
                    "Crack #": i_p,
                    "Confidence": round(float(p["confidence"]), 3),
                    "M·ª©c ƒë·ªô / Severity": estimate_severity(p, img_w, img_h),
                    "Width(px)": round(float(p["width"]), 1),
                    "Height(px)": round(float(p["height"]), 1),
                }
            )

        st.subheader("üîé Chi ti·∫øt v·∫øt n·ª©t / Crack details")
        if details:
            df_details = pd.DataFrame(details)
            st.dataframe(df_details, use_container_width=True)
        else:
            st.write(
                "Kh√¥ng c√≥ v√πng n√†o v∆∞·ª£t ng∆∞·ª°ng hi·ªÉn th·ªã / "
                "No region above threshold to show details."
            )

        # =====================================================
        # 6.3 BI·ªÇU ƒê·ªí K·∫æT QU·∫¢
        # =====================================================
        st.subheader("üìà Bi·ªÉu ƒë·ªì k·∫øt qu·∫£ / Result charts")

        fig, axs = plt.subplots(1, 2, figsize=(10, 4))

        # Bar chart confidence
        axs[0].bar(
            list(range(1, len(confs_all) + 1)),
            confs_all,
            color="#0ea5e9",
        )
        axs[0].set_title("Confidence t·ª´ng v√πng / per region")
        axs[0].set_xlabel("Region #")
        axs[0].set_ylabel("Confidence")
        axs[0].set_ylim(0, 1)

        # Pie chart: tr√™n ng∆∞·ª°ng vs d∆∞·ªõi ng∆∞·ª°ng
        above = len(preds_conf)
        below = len(preds) - above
        axs[1].pie(
            [above, below],
            labels=["‚â• threshold", "< threshold"],
            autopct="%1.0f%%",
            colors=["#22c55e", "#64748b"],
        )
        axs[1].set_title("Ph√¢n b·ªë v√πng n·ª©t / Crack distribution")

        st.pyplot(fig)

        # =====================================================
        # 6.4 T·∫†O PDF & N√öT DOWNLOAD
        # =====================================================
        tmp_dir = tempfile.gettempdir()
        orig_path = os.path.join(tmp_dir, f"bkai_orig_{idx}.png")
        ann_path = os.path.join(tmp_dir, f"bkai_ann_{idx}.png")
        chart_path = os.path.join(tmp_dir, f"bkai_chart_{idx}.png")
        pdf_path = os.path.join(tmp_dir, f"BKAI_Crack_Report_{idx}.pdf")

        image.save(orig_path)
        annotated.save(ann_path)
        fig.savefig(chart_path, bbox_inches="tight")
        plt.close(fig)

        export_report_pdf(pdf_path, orig_path, ann_path, df_summary, chart_path)

        with open(pdf_path, "rb") as f:
            st.download_button(
                label="üìÑ T·∫£i b√°o c√°o PDF / Download PDF report",
                data=f.read(),
                file_name=f"BKAI_Crack_Report_{idx}.pdf",
                mime="application/pdf",
            )

else:
    st.info("‚¨ÜÔ∏è Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t 1 ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch / Upload images to start.")
